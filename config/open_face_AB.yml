description: ""
name_exp : "dlib"
dataset : "PartA+PartB"
parent_folder: "/andromeda/shared/reco-pomigliano/tempo-gnn/tgcn/"
folder_data_path: "data/PartA/"
video_path: "data/PartA/video"
landmarks_path : "data/PartA/3dlandmarks/"
landmarks_npy: "data/PartA/landmarksnpy/"
csv_file: "data/PartA/samples.csv"
labels_path: "data/AB/labels_ab.npy"
data_path: "data/AB/dataset_openFaceAB.npy"

edges_path: "data/PartA/edges.npy"
filter_idx_90: ""
filter_idx_80: ""
#pathAB_test_a: "data/AB/test_a.npy"
#pathAB_test_b: "data/AB/test_b.npy"

# "data/PartA/idx_train_filterd_low_react.npy" 
#idx_train_all_subject
#idx_train_filterd_low_react
#idx_train_filterd
# "data/PartA/idx_test_filterd_low_react.npy"

weight_decay: 0.7
momentum: 0.9
step_decay: 10
L2: 0.0001
optimizer_name: 'SGD'

batch_size: 32
continue_training: False   #If set True will continue training from pretrained model
pretrain_model: "None" #"08-05-17:36" # #"08-03-12:18" #Name of folder that contains the model resume training
Temporal_downsampling: False
model_name: "aagcn" # "a3tgcn" # # #
embed_dim: 128
gru: 2
bn: True
lr: 0.01

num_subset: 2
num_features: 6
hidden_size: 1
N_sample: 17300
TS: 137
n_joints: 51
idx_train:  "data/AB/train_ab.npy" #  #"data/PartA/idx_train_filterd.npy"
idx_test:  "data/AB/test_a.npy" # #"data/PartA/idx_test_filterd.npy"
LOG_DIR: "log/AB"
t_kernel_size: 15
strid: 1
normalize_labels: False

adaptive: False
attention: True
drop_out: 0.2
protocol: "hold_out" #"hold_out" #"loso"  
maxMinNormalization: True #False #True

center_loss: False
augmentaion: False #True #False #  # True
prop: #1 # 1 #usando la classe di augmentation.
Aug_type: None #"all" #"all" #"r+f" #"all" # #"r+f" #"f" # [ "r" , "f" , "r+f","all"] None
concatenate: False # True #True #True # # # True
project_name: "pain_estimation_Jul"
log_name: "binary_AB_testA_stepD_10" 
gpu: 1
num_classes: 2
num_epoch: 200

eval_loso: False